[gpt3_ada_icl]
model_name_or_path = gpt3-ada
max_seq_length = 512
max_seq_length_eval = 2048
do_train = False
do_eval = True
do_predict = False
train_split = train
icl_only = True
evaluate_results = True

[gpt3_babbage_icl]
model_name_or_path = gpt3-babbage
max_seq_length = 512
max_seq_length_eval = 2048
do_train = False
do_eval = True
do_predict = False
train_split = train
icl_only = True
evaluate_results = True

[gpt3_curie_icl]
model_name_or_path = gpt3-curie
max_seq_length = 512
max_seq_length_eval = 2048
do_train = False
do_eval = True
do_predict = False
train_split = train
icl_only = True
evaluate_results = True

[gpt3_davinci_icl]
model_name_or_path = gpt3-davinci
max_seq_length = 512
max_seq_length_eval = 2048
do_train = False
do_eval = True
do_predict = False
train_split = train
icl_only = True
evaluate_results = True

[opt_125m_icl]
model_name_or_path = facebook/opt-125m
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 2
per_device_eval_batch_size = 2
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
num_beams = 4
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[opt_350m_icl]
model_name_or_path = facebook/opt-350m
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 2
per_device_eval_batch_size = 2
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
num_beams = 4
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[opt_2.7b_icl]
model_name_or_path = facebook/opt-2.7b
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 2
per_device_eval_batch_size = 2
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
num_beams = 4
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[opt_6.7b_icl]
model_name_or_path = facebook/opt-6.7b
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 2
per_device_eval_batch_size = 2
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
num_beams = 4
icl_only = True
num_prompt_ex = 8
evaluate_results = True


[opt_13b_icl]
model_name_or_path = facebook/opt-13b
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 2
per_device_eval_batch_size = 2
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[opt_30b_icl]
model_name_or_path = facebook/opt-30b
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 2
per_device_eval_batch_size = 2
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[opt_66b_icl]
model_name_or_path = facebook/opt-66b
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 2
per_device_eval_batch_size = 2
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[llama_7B_icl]
model_name_or_path = /scratch/gpfs/jp7224/llama/7B
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 1
per_device_eval_batch_size = 1
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
num_beams = 4
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[llama_13B_icl]
model_name_or_path = /scratch/gpfs/jp7224/llama/13B
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 1
per_device_eval_batch_size = 1
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
num_beams = 4
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[llama_30B_icl]
model_name_or_path = /scratch/gpfs/jp7224/llama/30B
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 1
per_device_eval_batch_size = 1
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
num_beams = 4
icl_only = True
num_prompt_ex = 8
evaluate_results = True

[llama_65B_icl]
model_name_or_path = /scratch/gpfs/jp7224/llama/65B
max_seq_length = 512
max_seq_length_eval = 2048
per_device_train_batch_size = 1
per_device_eval_batch_size = 1
do_train = False
do_eval = True
do_predict = False
train_split = train
episodes = 1
num_beams = 4
icl_only = True
num_prompt_ex = 8
evaluate_results = True

